"""
Классификация вопросов для LLM сервера
Без зависимостей от FastAPI - для тестирования
"""


def classify_question(text: str) -> str:
    """
    Классифицирует вопрос по типу: experience / technical / general
    """
    text_lower = text.lower()
    
    experience_keywords = [
        'опыт', 'работал', 'проект', 'делал', 'команда', 'задача',
        'ситуация', 'пример', 'как вы', 'расскажите о себе',
        'почему вы', 'ваш опыт', 'последний проект', 'достижения',
        'опишите', 'решили', 'сложную', 'справились', 'столкнулись'
    ]
    
    technical_keywords = [
        'что такое', 'как работает', 'объясни', 'разница между',
        'чем отличается', 'принцип', 'алгоритм', 'структура данных',
        'паттерн', 'зачем нужен', 'когда использовать', 'определение'
    ]
    
    exp_score = sum(1 for kw in experience_keywords if kw in text_lower)
    tech_score = sum(1 for kw in technical_keywords if kw in text_lower)
    
    if exp_score > tech_score and exp_score > 0:
        return 'experience'
    elif tech_score > exp_score and tech_score > 0:
        return 'technical'
    else:
        return 'general'


def get_max_tokens_for_type(question_type: str) -> int:
    """Возвращает рекомендуемое количество токенов по типу вопроса"""
    return {
        'experience': 900,   # Развёрнутые ответы с STAR
        'technical': 700,    # Определение + объяснение + пример
        'general': 500       # Краткие ответы
    }.get(question_type, 600)


def get_temperature_for_type(question_type: str) -> float:
    """Возвращает рекомендуемую temperature по типу вопроса"""
    return {
        'experience': 0.8,   # Более креативные ответы
        'technical': 0.5,    # Точные технические ответы
        'general': 0.7
    }.get(question_type, 0.7)


def build_contextual_prompt(question_type: str, user_context: str) -> str:
    """
    Строит развёрнутый промпт в зависимости от типа вопроса.
    Цель: качественные ответы на 1-2 минуты речи.
    """
    if question_type == 'experience':
        # STAR формат для вопросов про опыт
        context_full = user_context[:1000] if user_context else ''
        return (
            'Ты AI-ассистент для технических собеседований.\n\n'
            '## Формат ответа (STAR):\n'
            '1. **Ситуация**: опиши контекст (проект, команда, проблема)\n'
            '2. **Задача**: что конкретно нужно было сделать\n'
            '3. **Действия**: какие шаги предпринял, какие технологии использовал\n'
            '4. **Результат**: конкретные метрики (%, время, деньги)\n\n'
            '## Требования:\n'
            '- Длина: 200-300 слов (1.5-2 минуты речи)\n'
            '- Используй **жирный** для ключевых терминов\n'
            '- Опирайся на резюме, не придумывай факты\n'
            '- Приводи конкретные цифры и технологии\n\n'
            f'## Резюме кандидата:\n{context_full}'
        )
    elif question_type == 'technical':
        # Структурированный технический ответ
        return (
            'Ты AI-ассистент для технических собеседований.\n\n'
            '## Формат ответа:\n'
            '1. **Краткое определение** (1-2 предложения)\n'
            '2. **Подробное объяснение** (как работает, зачем нужно)\n'
            '3. **Пример из практики** (код или реальный кейс)\n\n'
            '## Требования:\n'
            '- Длина: 150-250 слов\n'
            '- Используй markdown: **жирный**, `код`, списки\n'
            '- Код оформляй в ```python блоках\n'
            '- Упоминай реальные use-cases из проектов'
        )
    else:
        # General — сбалансированный ответ
        context_short = user_context[:500] if user_context else ''
        return (
            'Ты AI-ассистент для технических собеседований.\n\n'
            '## Требования:\n'
            '- Длина: 100-200 слов\n'
            '- Формат: markdown\n'
            '- Тон: уверенный, профессиональный\n'
            '- Опирайся на контекст кандидата\n\n'
            f'## Контекст:\n{context_short}'
        )
